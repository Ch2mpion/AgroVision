{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**AgroVision - CNN Model** ğŸŒ¿\n",
        "\n",
        "- We'll be using PlantVillage as our primary dataset ğŸ–¼ï¸\n",
        "\n",
        "- Transfer Learning with MobileNetV2 âš¡\n",
        "\n",
        "- Adam's Optimizer [ Noise & Efficiency ] ğŸ’ª"
      ],
      "metadata": {
        "id": "FA4RSetAhAV5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"emmarex/plantdisease\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kdnScv7eYg6F",
        "outputId": "75ab7c83-ce3e-4a39-880c-726056bf5ed7"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Colab cache for faster access to the 'plantdisease' dataset.\n",
            "Path to dataset files: /kaggle/input/plantdisease\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Spliting Data into [ Train & Validation ]** ğŸ“‚"
      ],
      "metadata": {
        "id": "iEKqfMKgdgdG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install split-folders"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nfk5iqE4d9pO",
        "outputId": "c27fe63c-a6f7-43be-bbaf-61a33e08b8a0"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting split-folders\n",
            "  Downloading split_folders-0.5.1-py3-none-any.whl.metadata (6.2 kB)\n",
            "Downloading split_folders-0.5.1-py3-none-any.whl (8.4 kB)\n",
            "Installing collected packages: split-folders\n",
            "Successfully installed split-folders-0.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import splitfolders\n",
        "from pathlib import Path\n",
        "\n",
        "# 1. Define the path to your *current* unsplit dataset\n",
        "#    (This is the 'PlantVillage' folder from your screenshot)\n",
        "INPUT_FOLDER = Path(\"/kaggle/input/plantdisease/PlantVillage\")\n",
        "\n",
        "# 2. Define where you want the *new* split dataset to be created\n",
        "#    (We'll put it right where our training script expects it)\n",
        "OUTPUT_FOLDER = Path(\"/content/plant_dataset\")\n",
        "\n",
        "print(f\"Splitting files from {INPUT_FOLDER} into {OUTPUT_FOLDER}...\")\n",
        "\n",
        "# 3. Run the split\n",
        "#    This will split your data into 70% training and 30% validation\n",
        "#    (8,921 train vs 3,926 val is ~ 70/30)\n",
        "splitfolders.ratio(\n",
        "    INPUT_FOLDER,\n",
        "    output=OUTPUT_FOLDER,\n",
        "    seed=42,             # Gives a reproducible random split\n",
        "    ratio=(.7, .3),      # 70% training, 30% validation\n",
        "    group_prefix=None,   # No file grouping\n",
        "    move=False           # Copies files instead of moving (safer)\n",
        ")\n",
        "\n",
        "print(\"Done splitting! New folders are ready.\")\n",
        "print(f\"Your new training data is in: {OUTPUT_FOLDER / 'train'}\")\n",
        "print(f\"Your new validation data is in: {OUTPUT_FOLDER / 'val'}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1eVTLjwRdQkm",
        "outputId": "22e6e6eb-e85d-4468-9862-6c0a9706dd01"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Splitting files from /kaggle/input/plantdisease/PlantVillage into /content/plant_dataset...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Copying files: 20639 files [02:05, 164.51 files/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done splitting! New folders are ready.\n",
            "Your new training data is in: /content/plant_dataset/train\n",
            "Your new validation data is in: /content/plant_dataset/val\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Importing our Libraries for Training** ğŸ’»"
      ],
      "metadata": {
        "id": "3m3Urkb2fNnS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
        "from tensorflow.keras.layers import Input, Dense, GlobalAveragePooling2D, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.layers import RandomFlip, RandomRotation"
      ],
      "metadata": {
        "id": "OWh4OUUXd7DO"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "> Parameters Definition & Paths\n",
        "\n"
      ],
      "metadata": {
        "id": "pJhLgr5Hf3nq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 1. Define Parameters ---\n",
        "IMG_SIZE = (224, 224)\n",
        "BATCH_SIZE = 32\n",
        "TRAIN_DIR = 'plant_dataset/train'\n",
        "VAL_DIR = 'plant_dataset/val'\n",
        "\n",
        "# --- 2. Load Datasets ---\n",
        "# Keras will automatically label the data 0, 1, 2, 3 based on folder names\n",
        "train_dataset = image_dataset_from_directory(\n",
        "    TRAIN_DIR,\n",
        "    label_mode='int',\n",
        "    image_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "validation_dataset = image_dataset_from_directory(\n",
        "    VAL_DIR,\n",
        "    label_mode='int',\n",
        "    image_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "# Get the class names (Keras finds these from the folder names)\n",
        "class_names = train_dataset.class_names\n",
        "print(f\"Found class names: {class_names}\")\n",
        "\n",
        "NUM_CLASSES = len(class_names)\n",
        "print(f\"Successfully set number of classes to: {NUM_CLASSES}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xrNqJCKJfELc",
        "outputId": "97afd21c-f970-4a2a-fdd8-fee9a92dc2f5"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 14440 files belonging to 15 classes.\n",
            "Found 6198 files belonging to 15 classes.\n",
            "Found class names: ['Pepper__bell___Bacterial_spot', 'Pepper__bell___healthy', 'Potato___Early_blight', 'Potato___Late_blight', 'Potato___healthy', 'Tomato_Bacterial_spot', 'Tomato_Early_blight', 'Tomato_Late_blight', 'Tomato_Leaf_Mold', 'Tomato_Septoria_leaf_spot', 'Tomato_Spider_mites_Two_spotted_spider_mite', 'Tomato__Target_Spot', 'Tomato__Tomato_YellowLeaf__Curl_Virus', 'Tomato__Tomato_mosaic_virus', 'Tomato_healthy']\n",
            "Successfully set number of classes to: 15\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "> Data Preparation & Augmentation\n",
        "\n"
      ],
      "metadata": {
        "id": "JS-ln-QsgLOi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 3. Create a Data Augmentation Layer ---\n",
        "# This creates more training data by randomly flipping/rotating images\n",
        "# It helps the model generalize better and prevents overfitting.\n",
        "data_augmentation = tf.keras.Sequential([\n",
        "    RandomFlip('horizontal'),\n",
        "    RandomRotation(0.2),\n",
        "])\n",
        "\n",
        "# --- 4. Prepare Datasets for Performance ---\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "def prepare(ds, augment=False):\n",
        "    # Apply the MobileNetV2 preprocessing\n",
        "    ds = ds.map(lambda x, y: (tf.keras.applications.mobilenet_v2.preprocess_input(x), y),\n",
        "                num_parallel_calls=AUTOTUNE)\n",
        "\n",
        "    if augment:\n",
        "        ds = ds.map(lambda x, y: (data_augmentation(x, training=True), y),\n",
        "                    num_parallel_calls=AUTOTUNE)\n",
        "\n",
        "    # Use buffered prefetching for speed\n",
        "    return ds.prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "train_ds = prepare(train_dataset, augment=True)\n",
        "val_ds = prepare(validation_dataset)\n"
      ],
      "metadata": {
        "id": "Mi3eK46-gO6D"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "> Transfer Learning with MobileNetV2\n",
        "\n",
        "- *This gives a better Recognition*\n",
        "\n"
      ],
      "metadata": {
        "id": "wVNIFiROgmW8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 5. Build the Transfer Learning Model ---\n",
        "\n",
        "# Load MobileNetV2, pre-trained on ImageNet, but without its final classifier layer\n",
        "base_model = MobileNetV2(\n",
        "    input_shape=IMG_SIZE + (3,),\n",
        "    include_top=False, # <-- IMPORTANT\n",
        "    weights='imagenet'\n",
        ")\n",
        "\n",
        "# Freeze the base model. We don't want to re-train its weights.\n",
        "base_model.trainable = False\n",
        "\n",
        "# Create our new model on top\n",
        "inputs = Input(shape=IMG_SIZE + (3,))\n",
        "x = base_model(inputs, training=False) # Run in inference mode\n",
        "x = GlobalAveragePooling2D()(x) # Flattens the output\n",
        "x = Dropout(0.2)(x) # Regularization to prevent overfitting\n",
        "# Our new classifier layer. NUM_CLASSES (4) is the number of folders we have.\n",
        "outputs = Dense(NUM_CLASSES, activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs, outputs)\n",
        "\n",
        "# --- 6. Compile the Model ---\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "    loss='sparse_categorical_crossentropy', # Use this for integer labels\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 376
        },
        "id": "E2LZAFo9gP_L",
        "outputId": "eac5e18c-21b9-449b-d5f9-d56bd935686d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
            "\u001b[1m9406464/9406464\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ input_layer_2 (\u001b[38;5;33mInputLayer\u001b[0m)      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ mobilenetv2_1.00_224            â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m1280\u001b[0m)     â”‚     \u001b[38;5;34m2,257,984\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mFunctional\u001b[0m)                    â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ global_average_pooling2d        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)           â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout (\u001b[38;5;33mDropout\u001b[0m)               â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)           â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense (\u001b[38;5;33mDense\u001b[0m)                   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m)             â”‚        \u001b[38;5;34m19,215\u001b[0m â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ input_layer_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ mobilenetv2_1.00_224            â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)     â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,257,984</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)                    â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ global_average_pooling2d        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)           â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)           â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)             â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">19,215</span> â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,277,199\u001b[0m (8.69 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,277,199</span> (8.69 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m19,215\u001b[0m (75.06 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">19,215</span> (75.06 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,257,984\u001b[0m (8.61 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,257,984</span> (8.61 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "> Model Training âš™ï¸\n",
        "\n"
      ],
      "metadata": {
        "id": "uAB7vhSbiUkf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 7. Train the Model ---\n",
        "print(\"\\n--- Starting Model Training ---\")\n",
        "\n",
        "# This is where the model \"learns\" from your 8,921 images\n",
        "history = model.fit(\n",
        "    train_ds,\n",
        "    epochs=10, # Start with 10, you can increase this later\n",
        "    validation_data=val_ds\n",
        ")\n",
        "\n",
        "print(\"\\n--- Training Complete ---\")\n"
      ],
      "metadata": {
        "id": "8rNAOr2Cg3-L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "> Model Evaluation âœ…\n",
        "\n"
      ],
      "metadata": {
        "id": "JiwdAJ3dijUp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 8. Evaluate and Save ---\n",
        "\n",
        "# This will give you the FINAL statistics\n",
        "print(\"\\n--- Evaluating on Validation Set ---\")\n",
        "loss, accuracy = model.evaluate(val_ds)\n",
        "print(f\"Validation Accuracy: {accuracy * 100:.2f}%\")\n",
        "print(f\"Validation Loss: {loss:.4f}\")\n",
        "\n",
        "# Save your new, trained model!\n",
        "model.save('AgroVision.h5')\n",
        "print(\"\\nModel saved as 'AgroVision.h5'\")"
      ],
      "metadata": {
        "id": "ImgsKtX1iZYp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Rgs7oa8Zirgg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
